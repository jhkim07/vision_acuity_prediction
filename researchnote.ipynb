{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 모델과 Transformer의 목적, 성능, 특징 비교\n",
    "\n",
    "#### **1. Xception**\n",
    "- **목적**: \n",
    "  - 성능 향상과 계산 효율성을 위해 Depthwise Separable Convolution 도입.\n",
    "  - VGGNet과 ResNet의 단점을 개선하며, 더 가벼운 모델로 높은 정확도 목표.\n",
    "- **특징**:\n",
    "  - Depthwise Separable Convolution: 채널별 연산(Depthwise)과 채널 통합(Pointwise)로 연산량 감소.\n",
    "  - Residual Connection 사용.\n",
    "- **성능**:\n",
    "  - ImageNet에서 ResNet-152와 비슷하거나 더 좋은 성능을 기록하며 연산량 감소.\n",
    "  - Mobile 환경에 적합한 설계.\n",
    "- **장점**:\n",
    "  - 적은 파라미터와 높은 연산 효율.\n",
    "  - 복잡한 데이터에 잘 작동.\n",
    "- **단점**:\n",
    "  - 학습 초기에 더 많은 하이퍼파라미터 튜닝 필요.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. EfficientNet (B0 ~ B7)**\n",
    "- **목적**:\n",
    "  - 모델 크기(Depth, Width, Resolution) 스케일링 최적화.\n",
    "  - 더 적은 자원으로 높은 정확도를 달성.\n",
    "- **특징**:\n",
    "  - Compound Scaling: Depth, Width, Resolution을 균형적으로 조정.\n",
    "  - Efficient Swish Activation 사용.\n",
    "  - NAS(Neural Architecture Search)를 통해 설계.\n",
    "- **성능**:\n",
    "  - ImageNet에서 SOTA(State-of-the-Art)를 기록하며 높은 효율성.\n",
    "  - B7 기준으로 약 66M 파라미터로 높은 Top-1 정확도(84.4%).\n",
    "- **장점**:\n",
    "  - 작은 모델(EfficientNet-B0)도 뛰어난 성능.\n",
    "  - 다양한 스케일의 모델 제공.\n",
    "- **단점**:\n",
    "  - 학습 시간이 상대적으로 길며, 하드웨어 요구사항이 높을 수 있음.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. VGG (VGG16, VGG19)**\n",
    "- **목적**:\n",
    "  - 네트워크 깊이를 단순히 늘려 성능을 개선.\n",
    "  - CNN 설계에서 구조적 단순함 유지.\n",
    "- **특징**:\n",
    "  - 고정된 3x3 필터와 MaxPooling 사용.\n",
    "  - 네트워크가 매우 깊음(16~19 계층).\n",
    "  - Fully Connected Layers로 출력.\n",
    "- **성능**:\n",
    "  - ImageNet에서 높은 성능 기록(Top-5 Error 약 7.5%).\n",
    "  - ResNet 등 최신 모델 대비 성능은 낮음.\n",
    "- **장점**:\n",
    "  - 단순하고 이해하기 쉬운 설계.\n",
    "  - 적은 데이터셋에서도 성능이 비교적 안정적.\n",
    "- **단점**:\n",
    "  - 연산량과 메모리 사용량이 높아 대규모 데이터셋에서 비효율적.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. ResNet**\n",
    "- **목적**:\n",
    "  - 네트워크 깊이가 증가할수록 발생하는 Gradient Vanishing/Degradation 문제 해결.\n",
    "- **특징**:\n",
    "  - Residual Block: Identity Mapping으로 학습 효율 개선.\n",
    "  - 매우 깊은 네트워크(최대 1000+ 레이어)를 안정적으로 학습 가능.\n",
    "- **성능**:\n",
    "  - ImageNet 기준 ResNet-152 Top-5 Error: 3.57% (2015년 SOTA).\n",
    "  - Transfer Learning에서 강력한 성능.\n",
    "- **장점**:\n",
    "  - 다양한 컴퓨터 비전 작업에서 널리 사용.\n",
    "  - Transfer Learning에서 뛰어난 성능.\n",
    "- **단점**:\n",
    "  - Depth가 깊어질수록 메모리와 연산 자원 요구량 증가.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Vision Transformer (ViT)**\n",
    "- **목적**:\n",
    "  - Transformer 아키텍처를 비전 태스크에 도입.\n",
    "  - CNN의 지역적 성질 대신 글로벌한 관계 학습.\n",
    "- **특징**:\n",
    "  - 이미지를 패치(patch)로 나누고 이를 순차적으로 처리.\n",
    "  - Attention Mechanism 사용.\n",
    "  - Pretraining에 매우 많은 데이터 필요.\n",
    "- **성능**:\n",
    "  - 충분한 데이터가 주어지면 CNN 대비 성능 우수.\n",
    "  - ImageNet에서 Top-1 정확도 90% 이상 달성(대규모 모델 기준).\n",
    "- **장점**:\n",
    "  - 더 나은 전역적(글로벌) 컨텍스트 학습.\n",
    "  - 점점 더 다양한 응용 가능.\n",
    "- **단점**:\n",
    "  - 초기 학습 데이터 요구량이 매우 큼.\n",
    "  - 작은 데이터셋에서 CNN보다 학습 속도가 느리고 성능 낮음.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Swin Transformer**\n",
    "- **목적**:\n",
    "  - Vision Transformer의 지역적 특징 학습 문제를 개선.\n",
    "  - 패치 단위 학습(Local Attention) 도입.\n",
    "- **특징**:\n",
    "  - Shifted Window 기반 Attention.\n",
    "  - 더 적은 연산량으로 다양한 스케일에서 정보 학습.\n",
    "- **성능**:\n",
    "  - ImageNet, COCO 등에서 CNN을 능가하는 성능.\n",
    "  - Transformer 기반의 최신 SOTA 성능.\n",
    "- **장점**:\n",
    "  - 높은 확장성과 효율성.\n",
    "  - 다양한 비전 태스크에 적합.\n",
    "- **단점**:\n",
    "  - 일반 Transformer와 유사하게 대규모 학습 데이터 필요.\n",
    "\n",
    "---\n",
    "\n",
    "### **성능 및 목적 요약**\n",
    "\n",
    "| 모델                 | 주요 특징                               | 장점                                | 단점                            | 성능 (ImageNet Top-1) |\n",
    "|----------------------|----------------------------------------|-------------------------------------|---------------------------------|-----------------------|\n",
    "| **Xception**         | Depthwise Separable Conv.             | 효율적 연산, 높은 정확도            | 초기 튜닝 필요                  | ~79%                 |\n",
    "| **EfficientNet**     | Compound Scaling                     | 높은 효율성, 다양한 스케일 모델      | 학습 시간 길고 복잡             | ~84% (B7 기준)       |\n",
    "| **VGG**              | 단순한 계층 구조                      | 구조적 단순성, 적은 데이터에서 강점  | 연산량, 메모리 사용량 높음       | ~72% (VGG19 기준)    |\n",
    "| **ResNet**           | Residual Connection                  | 깊은 네트워크 안정적 학습           | 자원 요구량 증가                | ~78% (ResNet-152 기준)|\n",
    "| **Vision Transformer** | Transformer 기반 전역 학습          | 글로벌 관계 학습, 높은 확장성        | 데이터 요구량 많음              | ~90% (대규모 모델 기준)|\n",
    "| **Swin Transformer** | Shifted Window Attention             | 높은 효율성과 확장성                | 대규모 데이터 필요              | ~87%                 |\n",
    "\n",
    "---\n",
    "\n",
    "### **결론**\n",
    "- **데이터가 충분하고 복잡한 관계 학습**이 중요한 경우: **Vision Transformer (ViT)** 또는 **Swin Transformer**.\n",
    "- **연산 효율성과 경량화 모델**이 필요한 경우: **EfficientNet**.\n",
    "- **이해하기 쉬운 설계 및 적은 데이터**: **VGG**.\n",
    "- **Transfer Learning**에 강력한 모델: **ResNet**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **K-Fold 학습에서 가장 좋은 모델 선택**\n",
    "\n",
    "1. **Fold별 성능 추적**:\n",
    "   - 각 Fold에서 검증 데이터 성능(예: 정확도, F1-Score, Validation Loss 등)을 기록합니다.\n",
    "   - 기록한 성능을 기반으로 가장 좋은 모델을 선택합니다.\n",
    "\n",
    "2. **모델 저장**:\n",
    "   - 각 Fold에서 학습된 모델을 저장합니다. (예: `torch.save`)\n",
    "   - 성능 기준(예: 최고 검증 정확도)을 만족하는 모델만 저장하거나 모든 모델을 저장합니다.\n",
    "\n",
    "3. **가장 좋은 모델 확인**:\n",
    "   - 저장된 모델 중 성능이 가장 높은 모델을 로드하여 최종 테스트 데이터로 평가합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **코드 구현 예시**\n",
    "\n",
    "#### 2.1 K-Fold 학습 및 모델 저장\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 데이터 준비\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_val_accuracy = 0.0\n",
    "best_model_path = \"best_model.pth\"\n",
    "\n",
    "# Fold별 학습\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "    print(f\"\\nTraining Fold {fold + 1}/{kfold.n_splits}\")\n",
    "    \n",
    "    # 데이터 분리\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = create_model(num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 학습\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 검증\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_loader, criterion)\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # 가장 높은 검증 정확도의 모델 저장\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Best model saved with Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2.2 최적 모델 로드 및 테스트 평가\n",
    "최적의 모델을 저장한 후, 테스트 데이터에서 평가합니다.\n",
    "\n",
    "```python\n",
    "# 최적 모델 로드\n",
    "best_model = create_model(num_classes).to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.eval()\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_loss, test_accuracy = evaluate_model(best_model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **다른 방법: 모든 Fold 모델을 저장하고 평균 성능 계산**\n",
    "모든 Fold에서 학습된 모델을 저장한 후, 테스트 데이터에서 모든 모델의 평균 성능을 계산할 수도 있습니다.\n",
    "\n",
    "#### 3.1 모든 Fold 모델 저장\n",
    "```python\n",
    "model_paths = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "    model_path = f\"model_fold_{fold + 1}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model_paths.append(model_path)\n",
    "```\n",
    "\n",
    "#### 3.2 평균 성능 계산\n",
    "```python\n",
    "total_accuracy = 0.0\n",
    "for model_path in model_paths:\n",
    "    model = create_model(num_classes).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    _, test_accuracy = evaluate_model(model, test_loader, criterion)\n",
    "    total_accuracy += test_accuracy\n",
    "\n",
    "average_accuracy = total_accuracy / len(model_paths)\n",
    "print(f\"Average Test Accuracy: {average_accuracy:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **모델 저장 시 팁**\n",
    "- **모델 상태만 저장**: `torch.save(model.state_dict(), \"model.pth\")`\n",
    "  - 모델 구조가 동일한 코드에서 로드 가능.\n",
    "- **전체 모델 저장**: `torch.save(model, \"model_full.pth\")`\n",
    "  - 구조가 다른 코드에서도 로드 가능하지만, 덜 일반적임.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **결론**\n",
    "- **최적의 모델 저장**: K-Fold에서 검증 성능 기준으로 가장 높은 모델을 저장.\n",
    "- **모든 모델 저장**: 모든 Fold의 모델을 저장한 후, 평균 성능을 테스트 데이터에서 평가.\n",
    "- 선택은 프로젝트의 목적(최적 모델 단일 저장 vs. 여러 모델 성능 분석)에 따라 결정됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`model.train()`의 역할**\n",
    "1. **드롭아웃 (Dropout)**:\n",
    "   - 학습 중에는 드롭아웃 레이어가 활성화됩니다.\n",
    "   - 드롭아웃은 일부 뉴런의 출력을 랜덤하게 0으로 설정해 과적합(overfitting)을 방지하는 기법입니다.\n",
    "   - `model.train()`을 호출하지 않으면 드롭아웃이 작동하지 않아 모델 학습이 잘 되지 않을 수 있습니다.\n",
    "\n",
    "2. **배치 정규화 (Batch Normalization)**:\n",
    "   - 배치 정규화 레이어는 학습 중 배치 데이터의 평균(mean)과 분산(variance)을 사용합니다.\n",
    "   - `model.train()`이 호출되지 않으면 평가 모드의 평균과 분산(통계적 이동 평균값)을 사용하므로 학습 결과가 왜곡될 수 있습니다.\n",
    "\n",
    "3. **기타 레이어 동작 설정**:\n",
    "   - 일부 레이어는 학습 모드와 평가 모드에서 다른 동작을 합니다. 예를 들어, `Dropout`이나 `BatchNorm` 외에도 커스텀 레이어에서 `train()` 메서드를 통해 동작이 달라질 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **반대 동작: `model.eval()`**\n",
    "- 학습이 아닌 **평가 모드**로 전환합니다.\n",
    "- 드롭아웃과 배치 정규화 같은 레이어가 평가 모드로 전환됩니다.\n",
    "- 평가 시에는 모델의 출력을 고정하고, 불필요한 변화를 방지하기 위해 사용됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **왜 `model.train()`이 중요한가?**\n",
    "학습 모드에서만 활성화되는 동작(특히 Dropout과 Batch Normalization)을 제대로 설정하지 않으면 학습이 비정상적으로 진행될 수 있습니다. 따라서, **학습 시 반드시 `model.train()`을 호출**해야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **실제로 어떤 경우에 사용하는가?**\n",
    "- **훈련 루프 (Training Loop)**:\n",
    "  ```python\n",
    "  model.train()\n",
    "  for images, labels in train_loader:\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  ```\n",
    "\n",
    "- **평가 루프 (Validation/Test Loop)**:\n",
    "  ```python\n",
    "  model.eval()\n",
    "  with torch.no_grad():  # 평가 시 그래디언트 계산 비활성화\n",
    "      for images, labels in val_loader:\n",
    "          outputs = model(images)\n",
    "          # 성능 평가 코드...\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **요약**\n",
    "- **`model.train()`**: 학습 시 필요한 레이어 설정(드롭아웃, 배치 정규화)을 활성화.\n",
    "- **`model.eval()`**: 평가 시 레이어 설정을 고정.\n",
    "- 두 모드의 전환을 정확히 설정해야 학습과 평가가 올바르게 이루어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. **다중 레이블 분류 (Multi-label Classification)**\n",
    "   - 하나의 데이터가 **여러 클래스에 동시에 속할 수 있는 경우**.\n",
    "   - 예:\n",
    "     - **이미지 태그 예측**:\n",
    "       - 예: 고양이, 개, 새 등이 동시에 사진에 등장할 수 있음.\n",
    "       - 출력: `[0.8, 0.1, 0.5]` → 고양이 80%, 개 10%, 새 50%.\n",
    "     - **의학적 진단**:\n",
    "       - 한 환자가 여러 질병을 동시에 가질 수 있음.\n",
    "       - 출력: `[0.7, 0.3, 0.9]` → 심장병 70%, 당뇨 30%, 고혈압 90%.\n",
    "   - **레이블 간 관계**:\n",
    "     - 예: 심장병이 있으면 고혈압이 있을 가능성이 높다.\n",
    "     - 모델이 이러한 관계를 학습하여 더 높은 예측 성능을 제공.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **클래스 간 상호 배타적이지 않은 분류**\n",
    "   - 데이터가 **명확히 하나의 클래스에 속하지 않는 경우**.\n",
    "   - 예:\n",
    "     - **감정 분석**:\n",
    "       - 하나의 문장이 \"기쁨\"과 \"슬픔\" 같은 **혼합 감정**을 표현할 수 있음.\n",
    "       - 출력: `[0.4, 0.6]` → 기쁨 40%, 슬픔 60%.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **확률적 분류가 필요한 경우**\n",
    "   - **모델의 불확실성을 해석하고 싶을 때**.\n",
    "   - 예:\n",
    "     - **의료 진단**:\n",
    "       - 모델이 90% 확률로 암을 예측한 경우, 그 결과를 직접적으로 사용하거나, 전문가가 최종 판단에 참고할 수 있음.\n",
    "     - **자율 주행**:\n",
    "       - 자율 주행 차량이 특정 물체(예: 보행자, 자전거)를 인식할 때, 각 클래스의 확률로 표현하여 **의사 결정 알고리즘**에서 사용.\n",
    "   - **레이블 간 관계**:\n",
    "     - 도로에 보행자가 있는 경우, 근처에 자동차가 있을 확률이 높다는 관계를 학습.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **클래스 간 계층 구조가 있는 경우**\n",
    "   - 클래스 간 계층적 관계를 고려해야 하는 분류.\n",
    "   - 예:\n",
    "     - **동물 분류**:\n",
    "       - 레이블: \"포유류\", \"고양잇과\", \"사자\".\n",
    "       - 관계: \"사자\"는 \"고양잇과\"이고, \"고양잇과\"는 \"포유류\".\n",
    "     - 모델이 레이블의 계층 구조를 학습하여 더 나은 성능을 제공.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **클래스 불균형 문제 해결**\n",
    "   - 특정 클래스의 데이터가 부족한 경우, 확률적 해석이 중요해질 수 있음.\n",
    "   - 예:\n",
    "     - **사기 탐지**:\n",
    "       - 정상 거래와 사기 거래의 비율이 매우 다를 때, 확률 기반 출력은 사기 탐지의 민감도를 조정하는 데 유용.\n",
    "   - **레이블 간 관계**:\n",
    "     - 특정 거래 유형(예: 해외 결제)이 사기 거래일 가능성이 높다는 패턴을 학습.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **추천 시스템 (Recommendation Systems)**\n",
    "   - 유저가 여러 아이템을 선호하거나 관심을 가질 수 있음.\n",
    "   - 예:\n",
    "     - **영화 추천**:\n",
    "       - 모델이 사용자가 좋아할 영화의 확률을 예측: `[0.7, 0.1, 0.6]` → 영화 A(70%), 영화 B(10%), 영화 C(60%).\n",
    "       - 영화 간의 관계(예: 같은 장르)가 중요하게 작용.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **제너레이티브 모델 (Generative Models)**\n",
    "   - 예:\n",
    "     - **GANs**나 **VAEs**에서 이미지 생성 시, 클래스 레이블 간 관계를 학습하여 더 자연스러운 결과 생성.\n",
    "     - 예: \"고양이\"와 \"호랑이\"는 유사한 특징을 공유하며, 이를 기반으로 혼합 이미지를 생성.\n",
    "\n",
    "---\n",
    "\n",
    "### 결론\n",
    "- **다중 레이블 분류**와 **확률적 출력**이 중요한 문제(의료, 자율 주행, 감정 분석 등)에서 원핫 인코딩과 확률 기반 손실 함수를 사용하는 것이 효과적입니다.\n",
    "- 특히 **레이블 간의 관계**를 학습해야 하는 상황에서는 **다층 퍼셉트론**, **그래프 신경망(GNN)** 또는 **어텐션 기반 모델**을 고려하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **1. 다중 레이블 분류(Multi-label Classification) 출력 형식**\n",
    "\n",
    "**다중 레이블 분류(Multi-label Classification)**의 경우, 출력은 일반적으로 **각 클래스에 대한 독립적인 확률값(probability values)**로 표현됩니다. 이 출력값은 확률분포로 볼 수 있지만, **클래스 간 합이 반드시 1이 될 필요는 없습니다**. 각 클래스의 확률은 개별적으로 계산되기 때문에 **다양한 클래스가 동시에 활성화**될 수 있습니다.\n",
    "\n",
    "\n",
    "- 출력 텐서의 형태: `(batch_size, num_classes)`\n",
    "  - `batch_size`: 배치 크기\n",
    "  - `num_classes`: 예측하려는 클래스 수\n",
    "- 각 클래스에 대해 **[0, 1] 범위의 확률값**을 갖습니다.\n",
    "\n",
    "#### 예:\n",
    "```python\n",
    "# 모델 출력 (배치 크기=2, 클래스 개수=4)\n",
    "outputs = torch.tensor([[0.8, 0.1, 0.6, 0.2],  # 샘플 1에 대한 각 클래스 확률\n",
    "                        [0.3, 0.7, 0.2, 0.9]]) # 샘플 2에 대한 각 클래스 확률\n",
    "```\n",
    "- 첫 번째 샘플: 클래스 0(80%), 클래스 2(60%)가 활성화될 가능성이 높음.\n",
    "- 두 번째 샘플: 클래스 1(70%), 클래스 3(90%)가 활성화될 가능성이 높음.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 활성화 함수**\n",
    "- **`sigmoid`**:\n",
    "  - 다중 레이블 분류에서 각 클래스의 확률값을 독립적으로 계산합니다.\n",
    "  - `sigmoid`는 각 클래스의 출력값을 [0, 1]로 변환하므로, 각 클래스가 **동시에 활성화될 가능성**을 평가할 수 있습니다.\n",
    "  - **예**: 고양이(80%)와 개(70%)가 동시에 사진에 등장.\n",
    "\n",
    "```python\n",
    "outputs = torch.sigmoid(raw_outputs)  # 모델의 로짓(logits)을 확률로 변환\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 손실 함수**\n",
    "- **Binary Cross-Entropy (BCE) Loss**:\n",
    "  - 다중 레이블 분류에서 각 클래스에 대해 개별적으로 손실을 계산.\n",
    "  - 전체 손실은 클래스별 손실의 평균 또는 합으로 표현.\n",
    "\n",
    "```python\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss = criterion(raw_outputs, labels)  # raw_outputs는 로짓\n",
    "```\n",
    "\n",
    "#### 예:\n",
    "```python\n",
    "# 실제 레이블 (원핫 인코딩 형태)\n",
    "labels = torch.tensor([[1, 0, 1, 0],  # 샘플 1\n",
    "                       [0, 1, 0, 1]]) # 샘플 2\n",
    "\n",
    "# 모델 출력 (각 클래스에 대한 확률)\n",
    "outputs = torch.tensor([[0.8, 0.1, 0.6, 0.2],\n",
    "                        [0.3, 0.7, 0.2, 0.9]])\n",
    "\n",
    "# Binary Cross-Entropy Loss 계산\n",
    "loss = nn.BCELoss()(outputs, labels.float())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. 예측값 생성**\n",
    "- 확률값을 기준으로 **클래스별 활성화 여부를 판단**.\n",
    "- 일반적으로 **0.5**를 기준으로 활성화(1) 또는 비활성화(0)를 결정.\n",
    "  \n",
    "```python\n",
    "predicted = (outputs > 0.5).float()\n",
    "```\n",
    "\n",
    "#### 예:\n",
    "```python\n",
    "# 모델 출력\n",
    "outputs = torch.tensor([[0.8, 0.1, 0.6, 0.2],\n",
    "                        [0.3, 0.7, 0.2, 0.9]])\n",
    "\n",
    "# 활성화 여부 예측\n",
    "predicted = (outputs > 0.5).float()\n",
    "# 결과: [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. 다중 레이블 분류와 확률 해석**\n",
    "- 다중 레이블 분류는 출력값이 확률분포의 형태를 갖지만, 각 클래스는 **독립적으로** 확률값을 가집니다.\n",
    "- **출력값의 총합이 반드시 1일 필요는 없습니다**.\n",
    "- 모델은 **각 클래스에 대해 별도의 확률값을 학습**하여, 복합적인 클래스 활성화 상황을 처리합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. 다중 레이블 분류의 실제 활용 사례**\n",
    "- **이미지 태깅**: 사진에 나타난 여러 개체(예: 고양이, 개, 새)를 동시에 탐지.\n",
    "- **의학적 진단**: 환자가 여러 질병을 동시에 가질 가능성을 예측.\n",
    "- **추천 시스템**: 사용자가 관심을 가질 여러 아이템(예: 영화, 음악)을 동시에 추천.\n",
    "\n",
    "이처럼 **확률적 출력**은 다중 레이블 분류 문제를 해결하는 핵심 요소입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
